# Uncertainty-Aware Online Ensemble Transformer: Supplementary Materials
This repository contains supplementary materials for the paper *"Uncertainty-Aware Online Ensemble Transformer for Accurate Cloud Workload Forecasting in Predictive Auto-Scaling"*, including theoretical proofs and source code implementations.


## Document Structure
The repository is organized into two core directories to separate theoretical and practical components:

```
├── proof/                 # Theoretical proofs and mathematical derivations
│   └── Proof.pdf          # Formal proof of the proposed uncertainty quantifier's validity
└── code/                  # Source code implementation
    ├── ...
    ├── main.py            # Core experiment configuration and execution
    ├── requirements.txt   # Dependencies for environment setup
    ├── run.sh             # Script for basic forecasting experiments
    └── run_transfer.sh    # Script for transfer learning experiments

```


## Proof: Theoretical Validation
The `proof/` directory contains the key theoretical foundation of the proposed framework, documented in `Proof.pdf`. This file focuses on validating the **Adaptive Conformal Uncertainty Quantifier** proposed in the paper, with core contributions including:

### Key Theoretical Results
1. **Theorem 1**: Formalizes the convergence of the average miscoverage ratio of confidence intervals generated by the adaptive conformal quantifier, showing that it converges almost surely to the target miscoverage rate α as the number of time steps \( T \to \infty \):  
   \[
   \lim _{T \to \infty} \frac{1}{T} \sum_{t=1}^{T} \prod_{j=1}^{h}\left(x_{t}^{j} \notin \mathcal{C}_{t}^{j}\right) \stackrel{ a.s. }{=} \alpha
   \]

2. **Lemma 1**: Validates the conformal predictive distributions used in the framework, ensuring that the cumulative distribution function (CDF) constructed from calibration data satisfies the coverage guarantee \( \mathbb{P}_{Z}[\hat{F}_{j}(s_{j}) \leq 1-\alpha] = 1-\alpha \) for any \( 0 < \alpha < 1 \).

3. **Lemma 2**: Proves the stability of the adaptive miscoverage rate \( \alpha_t \) during online updates, showing that \( \alpha_t \) remains within the range \([-\gamma, 1+\gamma]\) with probability one and converges to the target α over time.

### Proof Methodology
The derivation builds on foundational work in conformal prediction [Vovk et al.(2005, 2017)] and adaptive inference [Gibbs and Candes(2021)], extending it to multi-step time series forecasting scenarios. It leverages exchangeability assumptions, multivariate quantile definitions, and online update rules to guarantee both validity and convergence of the uncertainty quantifier.


## Code: Implementation Details
The `code/` directory provides a complete implementation of the framework, supporting:
- Multiple state-of-the-art forecasting models (e.g., `onenet_fsnet`, `timesnet`, `dlinear`)
- Flexible configuration of sequence lengths, prediction horizons, and training parameters
- Online learning mode and transfer learning experiments
- Automated result saving for metrics, predictions, and ground truths

